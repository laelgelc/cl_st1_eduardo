{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810d9f10-ec19-4b09-8f90-e983e460b319",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://laelgelcpublic.s3.sa-east-1.amazonaws.com/lael_50_years_narrow_white.png.no_years.400px_96dpi.png\" width=\"300\" alt=\"LAEL 50 years logo\">\n",
    "<h3>APPLIED LINGUISTICS GRADUATE PROGRAMME (LAEL)</h3>\n",
    "</center>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888c2c96-2fc3-4a1a-995b-c388036a2a15",
   "metadata": {},
   "source": [
    "# Corpus Linguistics - Study 1 - Phase 1 - Eduardo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43e68a9-ed79-47fd-be36-c33b295a8ca7",
   "metadata": {},
   "source": [
    "# `Corpus de Vídeos de Divulgação Científica` (CVDC) _corpus_ compilation via `yt-dlp` and `webvtt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da30c9f-2e51-4a2b-8dd9-4ad2ce537d17",
   "metadata": {},
   "source": [
    "## Obtaining test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c9fb7-e317-4ae5-8577-617eb87e1db7",
   "metadata": {},
   "source": [
    "### Query to Copilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce491d6-8dad-4b9e-980f-6200fd0d9d7e",
   "metadata": {},
   "source": [
    "Hi! How are you doing, mate? I am conducting research about Portuguese language for scientific popularisation. Could you please find me a set of 100 YouTube videos in Portuguese that explain about the following scientific topics in an easy to understand way, in other words, that use language that is accessible and engrossing to lay people?\n",
    "- Linguística de Corpus\n",
    "- Análise Multidimensional\n",
    "- Discurso\n",
    "- Infodemia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5637d2-199f-40ca-bd68-0eea338f5172",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e66025-979c-41c3-b560-9077f5afb22a",
   "metadata": {},
   "source": [
    "Copilot's response can be found here: [YouTube Videos on Linguistics and Discourse Analysis in Portuguese](https://copilot.microsoft.com/sl/1lnaMfI52i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d3d74-e3a2-45ed-9749-ffcaed2acb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvdc_videos = {\n",
    "    'Apresentando a Linguística de Corpus': 'https://youtu.be/QiyQHUGgmi4?si=NqkPQl3I0h-bPuyt',\n",
    "    'O que é Linguística de Corpus?': 'https://youtu.be/FxCwGq9DW7M?si=h-2B4TQgAijfhjbC',\n",
    "    'Aula aberta - Linguística de Corpus para Tradutores': 'https://www.youtube.com/live/heo2D5Rk018?si=sSrdejM7XhTm8yuO',\n",
    "    'Análise do discurso - Coleção linguística para ensino superior.': 'https://youtu.be/BIKhTvCNzfw?si=5440D6A_P_X30_Ob',\n",
    "    'Linguística IV Aula 01 Introduçãoà Análise do Discurso': 'https://youtu.be/NWYO-K-cWkk?si=7fClDaFRWwmd9Wr6'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d88c03-5604-4cdc-b1fc-4e0482ef5191",
   "metadata": {},
   "source": [
    "## What is `yt-dlp`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495cc745-08b9-4976-944d-51e6f66b4483",
   "metadata": {},
   "source": [
    "yt-dlp is a feature-rich command-line audio/video downloader.\n",
    "\n",
    "Please refer to:\n",
    "\n",
    "- [yt-dlp](https://github.com/yt-dlp/yt-dlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9fb300-f325-46ba-960a-6611e387ef30",
   "metadata": {},
   "source": [
    "Note: `yt-dlp` has strong [dependency](https://github.com/yt-dlp/yt-dlp?tab=readme-ov-file#dependencies) with:\n",
    "- [ffmpeg](https://www.ffmpeg.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57565048-e0b5-4799-8717-010f9fa3ad70",
   "metadata": {},
   "source": [
    "## What is WebVTT?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3074fd91-94c1-461b-8071-caee847df307",
   "metadata": {},
   "source": [
    "The **Web Video Text Tracks Format (WebVTT)** is a format for displaying timed text tracks (such as subtitles or captions) using the HTML <track> element.\n",
    "\n",
    "Please refer to:\n",
    "- [Web Video Text Tracks Format (WebVTT)](https://developer.mozilla.org/en-US/docs/Web/API/WebVTT_API)\n",
    "- [WebVTT: The Web Video Text Tracks Format](https://www.w3.org/TR/webvtt1/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c91ab-2890-4dad-a464-bb74dfae5e29",
   "metadata": {},
   "source": [
    "`webvtt-py` is a Python package for reading/writing WebVTT caption files.\n",
    "\n",
    "Please refer to:\n",
    "- [webvtt-py](https://pypi.org/project/webvtt-py/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c33e22-a38b-46b4-b11f-8502215dfbc7",
   "metadata": {},
   "source": [
    "## Required Python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44513d8c-d0aa-48ab-ab3b-c87fa8940b57",
   "metadata": {},
   "source": [
    "- pandas\n",
    "- demoji\n",
    "- webvtt-py\n",
    "- yt-dlp\n",
    "\n",
    "Install them in a Python enviroment. In this solution, this environment was named `my_env`, as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593f06a-6728-4467-976c-aa5a76330da2",
   "metadata": {},
   "source": [
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ sudo apt update && sudo apt upgrade -y\n",
    "<omitted>\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ sudo apt install -y python3-pip python3-venv ripgrep html2text zip unzip pipx ffmpeg\n",
    "<omitted>\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ python3 -m venv my_env\n",
    "<omitted>\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ pip install demoji pandas webvtt-py yt-dlp\n",
    "<omitted>\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ deactivate\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84468b1-839f-4877-9c14-8ae84ba201e5",
   "metadata": {},
   "source": [
    "## Using `yt-dlp` to collect captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce0eee7-e256-49d1-b644-b7f70f6402a9",
   "metadata": {},
   "source": [
    "Activate the `my_env` environment\n",
    "\n",
    "```\n",
    "eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ source \"$HOME\"/my_env/bin/activate\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d9a377-b3c1-4be7-95d8-2a9f2cba8ef4",
   "metadata": {},
   "source": [
    "### Listing available automatic captions of a specific YouTube video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f22699-a9b2-40ff-abe4-6d9d7d93b4ea",
   "metadata": {},
   "source": [
    "Note that the desired automatic caption in this project is `pt-orig`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c686b6-33b6-48df-868a-b58aa05946dd",
   "metadata": {},
   "source": [
    "`\n",
    "yt-dlp --list-subs \"https://youtu.be/QiyQHUGgmi4?si=NqkPQl3I0h-bPuyt\"\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d24b84-1f42-4a5c-927b-6cae92fc5345",
   "metadata": {},
   "source": [
    "```\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads$ cd cl_st1_eduardo\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_eduardo$ yt-dlp --list-subs \"https://youtu.be/QiyQHUGgmi4?si=NqkPQl3I0h-bPuyt\"\n",
    "[youtube] Extracting URL: https://youtu.be/QiyQHUGgmi4?si=NqkPQl3I0h-bPuyt\n",
    "[youtube] QiyQHUGgmi4: Downloading webpage\n",
    "[youtube] QiyQHUGgmi4: Downloading ios player API JSON\n",
    "[youtube] QiyQHUGgmi4: Downloading web creator player API JSON\n",
    "[youtube] QiyQHUGgmi4: Downloading m3u8 information\n",
    "[info] Available automatic captions for QiyQHUGgmi4:\n",
    "Language Name                  Formats\n",
    "ab       Abkhazian             vtt, ttml, srv3, srv2, srv1, json3\n",
    "aa       Afar                  vtt, ttml, srv3, srv2, srv1, json3\n",
    "af       Afrikaans             vtt, ttml, srv3, srv2, srv1, json3\n",
    "ak       Akan                  vtt, ttml, srv3, srv2, srv1, json3\n",
    "sq       Albanian              vtt, ttml, srv3, srv2, srv1, json3\n",
    "am       Amharic               vtt, ttml, srv3, srv2, srv1, json3\n",
    "ar       Arabic                vtt, ttml, srv3, srv2, srv1, json3\n",
    "hy       Armenian              vtt, ttml, srv3, srv2, srv1, json3\n",
    "as       Assamese              vtt, ttml, srv3, srv2, srv1, json3\n",
    "ay       Aymara                vtt, ttml, srv3, srv2, srv1, json3\n",
    "az       Azerbaijani           vtt, ttml, srv3, srv2, srv1, json3\n",
    "bn       Bangla                vtt, ttml, srv3, srv2, srv1, json3\n",
    "ba       Bashkir               vtt, ttml, srv3, srv2, srv1, json3\n",
    "eu       Basque                vtt, ttml, srv3, srv2, srv1, json3\n",
    "be       Belarusian            vtt, ttml, srv3, srv2, srv1, json3\n",
    "bho      Bhojpuri              vtt, ttml, srv3, srv2, srv1, json3\n",
    "bs       Bosnian               vtt, ttml, srv3, srv2, srv1, json3\n",
    "br       Breton                vtt, ttml, srv3, srv2, srv1, json3\n",
    "bg       Bulgarian             vtt, ttml, srv3, srv2, srv1, json3\n",
    "my       Burmese               vtt, ttml, srv3, srv2, srv1, json3\n",
    "ca       Catalan               vtt, ttml, srv3, srv2, srv1, json3\n",
    "ceb      Cebuano               vtt, ttml, srv3, srv2, srv1, json3\n",
    "zh-Hans  Chinese (Simplified)  vtt, ttml, srv3, srv2, srv1, json3\n",
    "zh-Hant  Chinese (Traditional) vtt, ttml, srv3, srv2, srv1, json3\n",
    "co       Corsican              vtt, ttml, srv3, srv2, srv1, json3\n",
    "hr       Croatian              vtt, ttml, srv3, srv2, srv1, json3\n",
    "cs       Czech                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "da       Danish                vtt, ttml, srv3, srv2, srv1, json3\n",
    "dv       Divehi                vtt, ttml, srv3, srv2, srv1, json3\n",
    "nl       Dutch                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "dz       Dzongkha              vtt, ttml, srv3, srv2, srv1, json3\n",
    "en       English               vtt, ttml, srv3, srv2, srv1, json3\n",
    "eo       Esperanto             vtt, ttml, srv3, srv2, srv1, json3\n",
    "et       Estonian              vtt, ttml, srv3, srv2, srv1, json3\n",
    "ee       Ewe                   vtt, ttml, srv3, srv2, srv1, json3\n",
    "fo       Faroese               vtt, ttml, srv3, srv2, srv1, json3\n",
    "fj       Fijian                vtt, ttml, srv3, srv2, srv1, json3\n",
    "fil      Filipino              vtt, ttml, srv3, srv2, srv1, json3\n",
    "fi       Finnish               vtt, ttml, srv3, srv2, srv1, json3\n",
    "fr       French                vtt, ttml, srv3, srv2, srv1, json3\n",
    "gaa      Ga                    vtt, ttml, srv3, srv2, srv1, json3\n",
    "gl       Galician              vtt, ttml, srv3, srv2, srv1, json3\n",
    "lg       Ganda                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "ka       Georgian              vtt, ttml, srv3, srv2, srv1, json3\n",
    "de       German                vtt, ttml, srv3, srv2, srv1, json3\n",
    "el       Greek                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "gn       Guarani               vtt, ttml, srv3, srv2, srv1, json3\n",
    "gu       Gujarati              vtt, ttml, srv3, srv2, srv1, json3\n",
    "ht       Haitian Creole        vtt, ttml, srv3, srv2, srv1, json3\n",
    "ha       Hausa                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "haw      Hawaiian              vtt, ttml, srv3, srv2, srv1, json3\n",
    "iw       Hebrew                vtt, ttml, srv3, srv2, srv1, json3\n",
    "hi       Hindi                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "hmn      Hmong                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "hu       Hungarian             vtt, ttml, srv3, srv2, srv1, json3\n",
    "is       Icelandic             vtt, ttml, srv3, srv2, srv1, json3\n",
    "ig       Igbo                  vtt, ttml, srv3, srv2, srv1, json3\n",
    "id       Indonesian            vtt, ttml, srv3, srv2, srv1, json3\n",
    "ga       Irish                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "it       Italian               vtt, ttml, srv3, srv2, srv1, json3\n",
    "ja       Japanese              vtt, ttml, srv3, srv2, srv1, json3\n",
    "jv       Javanese              vtt, ttml, srv3, srv2, srv1, json3\n",
    "kl       Kalaallisut           vtt, ttml, srv3, srv2, srv1, json3\n",
    "kn       Kannada               vtt, ttml, srv3, srv2, srv1, json3\n",
    "kk       Kazakh                vtt, ttml, srv3, srv2, srv1, json3\n",
    "kha      Khasi                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "km       Khmer                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "rw       Kinyarwanda           vtt, ttml, srv3, srv2, srv1, json3\n",
    "ko       Korean                vtt, ttml, srv3, srv2, srv1, json3\n",
    "kri      Krio                  vtt, ttml, srv3, srv2, srv1, json3\n",
    "ku       Kurdish               vtt, ttml, srv3, srv2, srv1, json3\n",
    "ky       Kyrgyz                vtt, ttml, srv3, srv2, srv1, json3\n",
    "lo       Lao                   vtt, ttml, srv3, srv2, srv1, json3\n",
    "la       Latin                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "lv       Latvian               vtt, ttml, srv3, srv2, srv1, json3\n",
    "ln       Lingala               vtt, ttml, srv3, srv2, srv1, json3\n",
    "lt       Lithuanian            vtt, ttml, srv3, srv2, srv1, json3\n",
    "luo      Luo                   vtt, ttml, srv3, srv2, srv1, json3\n",
    "lb       Luxembourgish         vtt, ttml, srv3, srv2, srv1, json3\n",
    "mk       Macedonian            vtt, ttml, srv3, srv2, srv1, json3\n",
    "mg       Malagasy              vtt, ttml, srv3, srv2, srv1, json3\n",
    "ms       Malay                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "ml       Malayalam             vtt, ttml, srv3, srv2, srv1, json3\n",
    "mt       Maltese               vtt, ttml, srv3, srv2, srv1, json3\n",
    "gv       Manx                  vtt, ttml, srv3, srv2, srv1, json3\n",
    "mi       Māori                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "mr       Marathi               vtt, ttml, srv3, srv2, srv1, json3\n",
    "mn       Mongolian             vtt, ttml, srv3, srv2, srv1, json3\n",
    "mfe      Morisyen              vtt, ttml, srv3, srv2, srv1, json3\n",
    "ne       Nepali                vtt, ttml, srv3, srv2, srv1, json3\n",
    "new      Newari                vtt, ttml, srv3, srv2, srv1, json3\n",
    "nso      Northern Sotho        vtt, ttml, srv3, srv2, srv1, json3\n",
    "no       Norwegian             vtt, ttml, srv3, srv2, srv1, json3\n",
    "ny       Nyanja                vtt, ttml, srv3, srv2, srv1, json3\n",
    "oc       Occitan               vtt, ttml, srv3, srv2, srv1, json3\n",
    "or       Odia                  vtt, ttml, srv3, srv2, srv1, json3\n",
    "om       Oromo                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "os       Ossetic               vtt, ttml, srv3, srv2, srv1, json3\n",
    "pam      Pampanga              vtt, ttml, srv3, srv2, srv1, json3\n",
    "ps       Pashto                vtt, ttml, srv3, srv2, srv1, json3\n",
    "fa       Persian               vtt, ttml, srv3, srv2, srv1, json3\n",
    "pl       Polish                vtt, ttml, srv3, srv2, srv1, json3\n",
    "pt-orig  Portuguese (Original) vtt, ttml, srv3, srv2, srv1, json3\n",
    "pt       Portuguese            vtt, ttml, srv3, srv2, srv1, json3\n",
    "pt-PT    Portuguese (Portugal) vtt, ttml, srv3, srv2, srv1, json3\n",
    "pa       Punjabi               vtt, ttml, srv3, srv2, srv1, json3\n",
    "qu       Quechua               vtt, ttml, srv3, srv2, srv1, json3\n",
    "ro       Romanian              vtt, ttml, srv3, srv2, srv1, json3\n",
    "rn       Rundi                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "ru       Russian               vtt, ttml, srv3, srv2, srv1, json3\n",
    "sm       Samoan                vtt, ttml, srv3, srv2, srv1, json3\n",
    "sg       Sango                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "sa       Sanskrit              vtt, ttml, srv3, srv2, srv1, json3\n",
    "gd       Scottish Gaelic       vtt, ttml, srv3, srv2, srv1, json3\n",
    "sr       Serbian               vtt, ttml, srv3, srv2, srv1, json3\n",
    "crs      Seselwa Creole French vtt, ttml, srv3, srv2, srv1, json3\n",
    "sn       Shona                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "sd       Sindhi                vtt, ttml, srv3, srv2, srv1, json3\n",
    "si       Sinhala               vtt, ttml, srv3, srv2, srv1, json3\n",
    "sk       Slovak                vtt, ttml, srv3, srv2, srv1, json3\n",
    "sl       Slovenian             vtt, ttml, srv3, srv2, srv1, json3\n",
    "so       Somali                vtt, ttml, srv3, srv2, srv1, json3\n",
    "st       Southern Sotho        vtt, ttml, srv3, srv2, srv1, json3\n",
    "es       Spanish               vtt, ttml, srv3, srv2, srv1, json3\n",
    "su       Sundanese             vtt, ttml, srv3, srv2, srv1, json3\n",
    "sw       Swahili               vtt, ttml, srv3, srv2, srv1, json3\n",
    "ss       Swati                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "sv       Swedish               vtt, ttml, srv3, srv2, srv1, json3\n",
    "tg       Tajik                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "ta       Tamil                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "tt       Tatar                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "te       Telugu                vtt, ttml, srv3, srv2, srv1, json3\n",
    "th       Thai                  vtt, ttml, srv3, srv2, srv1, json3\n",
    "bo       Tibetan               vtt, ttml, srv3, srv2, srv1, json3\n",
    "ti       Tigrinya              vtt, ttml, srv3, srv2, srv1, json3\n",
    "to       Tongan                vtt, ttml, srv3, srv2, srv1, json3\n",
    "ts       Tsonga                vtt, ttml, srv3, srv2, srv1, json3\n",
    "tn       Tswana                vtt, ttml, srv3, srv2, srv1, json3\n",
    "tum      Tumbuka               vtt, ttml, srv3, srv2, srv1, json3\n",
    "tr       Turkish               vtt, ttml, srv3, srv2, srv1, json3\n",
    "tk       Turkmen               vtt, ttml, srv3, srv2, srv1, json3\n",
    "uk       Ukrainian             vtt, ttml, srv3, srv2, srv1, json3\n",
    "ur       Urdu                  vtt, ttml, srv3, srv2, srv1, json3\n",
    "ug       Uyghur                vtt, ttml, srv3, srv2, srv1, json3\n",
    "uz       Uzbek                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "ve       Venda                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "vi       Vietnamese            vtt, ttml, srv3, srv2, srv1, json3\n",
    "war      Waray                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "cy       Welsh                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "fy       Western Frisian       vtt, ttml, srv3, srv2, srv1, json3\n",
    "wo       Wolof                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "xh       Xhosa                 vtt, ttml, srv3, srv2, srv1, json3\n",
    "yi       Yiddish               vtt, ttml, srv3, srv2, srv1, json3\n",
    "yo       Yoruba                vtt, ttml, srv3, srv2, srv1, json3\n",
    "zu       Zulu                  vtt, ttml, srv3, srv2, srv1, json3\n",
    "QiyQHUGgmi4 has no subtitles\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_eduardo$ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf557a23-c0aa-4021-9c02-cefe3313c7e4",
   "metadata": {},
   "source": [
    "### Downloading the captions in `pt-orig` from a specific YouTube video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b31e6-9f58-408a-a7ff-4bfe6f9b85cf",
   "metadata": {},
   "source": [
    "`\n",
    "yt-dlp --write-auto-sub --sub-lang pt-orig --sub-format vtt --skip-download \"https://youtu.be/QiyQHUGgmi4?si=NqkPQl3I0h-bPuyt\"\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7691069-1d36-4918-897c-a561f678cb9b",
   "metadata": {},
   "source": [
    "```\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_eduardo$ yt-dlp --write-auto-sub --sub-lang pt-orig --sub-format vtt --skip-download \"https://youtu.be/QiyQHUGgmi4?si=NqkPQl3I0h-bPuyt\"\n",
    "[youtube] Extracting URL: https://youtu.be/QiyQHUGgmi4?si=NqkPQl3I0h-bPuyt\n",
    "[youtube] QiyQHUGgmi4: Downloading webpage\n",
    "[youtube] QiyQHUGgmi4: Downloading ios player API JSON\n",
    "[youtube] QiyQHUGgmi4: Downloading web creator player API JSON\n",
    "[youtube] QiyQHUGgmi4: Downloading m3u8 information\n",
    "[info] QiyQHUGgmi4: Downloading subtitles: pt-orig\n",
    "[info] QiyQHUGgmi4: Downloading 1 format(s): 605+140\n",
    "Deleting existing file Apresentando a Linguística de Corpus [QiyQHUGgmi4].pt-orig.vtt\n",
    "[info] Writing video subtitles to: Apresentando a Linguística de Corpus [QiyQHUGgmi4].pt-orig.vtt\n",
    "[download] Destination: Apresentando a Linguística de Corpus [QiyQHUGgmi4].pt-orig.vtt\n",
    "[download] 100% of   17.05KiB in 00:00:00 at 131.60KiB/s\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_eduardo$ ll\n",
    "total 1355677\n",
    "drwxrwxrwx 1 eyamrog eyamrog       512 Aug  7 17:18  ./\n",
    "drwxrwxrwx 1 eyamrog eyamrog       512 Jul 19 07:37  ../\n",
    "-rwxrwxrwx 1 eyamrog eyamrog     17459 Aug  7 17:18 'Apresentando a Linguística de Corpus [QiyQHUGgmi4].pt-orig.vtt'*\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_eduardo$ \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763054e1-d81f-41c1-b9f5-f3b0b346a82c",
   "metadata": {},
   "source": [
    "### Downloading the captions in `pt-orig` from all the videos in a YouTube playlist in separate directory indexed by video order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163099e2-2187-49d6-952c-f9e7c027f05e",
   "metadata": {},
   "source": [
    "`\n",
    "yt-dlp --write-auto-sub --sub-lang pt-orig --sub-format vtt --skip-download -o \"%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s\" \"https://www.youtube.com/playlist?list=PLl1do-8RrfNzTg7BhtiIOgAa7XTW9Rx_A\"\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e387090d-a1ec-43a7-8524-90f27dcd506b",
   "metadata": {},
   "source": [
    "```\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_eduardo$ yt-dlp --write-auto-sub --sub-lang pt-orig --sub-format vtt --skip-download -o \"%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s\" \"https://www.youtube.com/playlist?list=PLl1do-8RrfNzTg7BhtiIOgAa7XTW9Rx_A\"\n",
    "[youtube:tab] Extracting URL: https://www.youtube.com/playlist?list=PLl1do-8RrfNzTg7BhtiIOgAa7XTW9Rx_A\n",
    "[youtube:tab] PLl1do-8RrfNzTg7BhtiIOgAa7XTW9Rx_A: Downloading webpage\n",
    "[youtube:tab] PLl1do-8RrfNzTg7BhtiIOgAa7XTW9Rx_A: Redownloading playlist API JSON with unavailable videos\n",
    "[download] Downloading playlist: cl_st1_eduardo_cvdc\n",
    "[youtube:tab] PLl1do-8RrfNzTg7BhtiIOgAa7XTW9Rx_A page 1: Downloading API JSON\n",
    "WARNING: [youtube:tab] Incomplete data received. Retrying (1/3)...\n",
    "[youtube:tab] PLl1do-8RrfNzTg7BhtiIOgAa7XTW9Rx_A page 1: Downloading API JSON\n",
    "WARNING: [youtube:tab] Incomplete data received. Retrying (2/3)...\n",
    "[youtube:tab] PLl1do-8RrfNzTg7BhtiIOgAa7XTW9Rx_A page 1: Downloading API JSON\n",
    "WARNING: [youtube:tab] Incomplete data received. Retrying (3/3)...\n",
    "[youtube:tab] PLl1do-8RrfNzTg7BhtiIOgAa7XTW9Rx_A page 1: Downloading API JSON\n",
    "WARNING: [youtube:tab] Incomplete data received. Giving up after 3 retries\n",
    "[youtube:tab] Playlist cl_st1_eduardo_cvdc: Downloading 5 items of 5\n",
    "[download] Downloading item 1 of 5\n",
    "[youtube] Extracting URL: https://www.youtube.com/watch?v=QiyQHUGgmi4\n",
    "[youtube] QiyQHUGgmi4: Downloading webpage\n",
    "[youtube] QiyQHUGgmi4: Downloading ios player API JSON\n",
    "[youtube] QiyQHUGgmi4: Downloading web creator player API JSON\n",
    "[youtube] QiyQHUGgmi4: Downloading m3u8 information\n",
    "[info] QiyQHUGgmi4: Downloading subtitles: pt-orig\n",
    "[info] QiyQHUGgmi4: Downloading 1 format(s): 605+140\n",
    "Deleting existing file cl_st1_eduardo_cvdc/1 - Apresentando a Linguística de Corpus.pt-orig.vtt\n",
    "[info] Writing video subtitles to: cl_st1_eduardo_cvdc/1 - Apresentando a Linguística de Corpus.pt-orig.vtt\n",
    "[download] Destination: cl_st1_eduardo_cvdc/1 - Apresentando a Linguística de Corpus.pt-orig.vtt\n",
    "[download] 100% of   17.05KiB in 00:00:00 at 194.87KiB/s\n",
    "[download] Downloading item 2 of 5\n",
    "[youtube] Extracting URL: https://www.youtube.com/watch?v=FxCwGq9DW7M\n",
    "[youtube] FxCwGq9DW7M: Downloading webpage\n",
    "[youtube] FxCwGq9DW7M: Downloading ios player API JSON\n",
    "[youtube] FxCwGq9DW7M: Downloading web creator player API JSON\n",
    "[youtube] FxCwGq9DW7M: Downloading m3u8 information\n",
    "[info] FxCwGq9DW7M: Downloading subtitles: pt-orig\n",
    "[info] FxCwGq9DW7M: Downloading 1 format(s): 605+140\n",
    "Deleting existing file cl_st1_eduardo_cvdc/2 - O que é Linguística de Corpus？.pt-orig.vtt\n",
    "[info] Writing video subtitles to: cl_st1_eduardo_cvdc/2 - O que é Linguística de Corpus？.pt-orig.vtt\n",
    "[download] Destination: cl_st1_eduardo_cvdc/2 - O que é Linguística de Corpus？.pt-orig.vtt\n",
    "[download] 100% of   28.66KiB in 00:00:00 at 238.72KiB/s\n",
    "[download] Downloading item 3 of 5\n",
    "[youtube] Extracting URL: https://www.youtube.com/watch?v=heo2D5Rk018\n",
    "[youtube] heo2D5Rk018: Downloading webpage\n",
    "[youtube] heo2D5Rk018: Downloading ios player API JSON\n",
    "[youtube] heo2D5Rk018: Downloading web creator player API JSON\n",
    "[youtube] heo2D5Rk018: Downloading m3u8 information\n",
    "[info] heo2D5Rk018: Downloading subtitles: pt-orig\n",
    "[info] heo2D5Rk018: Downloading 1 format(s): 136+251\n",
    "Deleting existing file cl_st1_eduardo_cvdc/3 - Aula aberta - Linguística de Corpus para Tradutores.pt-orig.vtt\n",
    "[info] Writing video subtitles to: cl_st1_eduardo_cvdc/3 - Aula aberta - Linguística de Corpus para Tradutores.pt-orig.vtt\n",
    "[download] Destination: cl_st1_eduardo_cvdc/3 - Aula aberta - Linguística de Corpus para Tradutores.pt-orig.vtt\n",
    "[download] 100% of  536.31KiB in 00:00:00 at 1.50MiB/s\n",
    "[download] Downloading item 4 of 5\n",
    "[youtube] Extracting URL: https://www.youtube.com/watch?v=BIKhTvCNzfw\n",
    "[youtube] BIKhTvCNzfw: Downloading webpage\n",
    "[youtube] BIKhTvCNzfw: Downloading ios player API JSON\n",
    "[youtube] BIKhTvCNzfw: Downloading web creator player API JSON\n",
    "[youtube] BIKhTvCNzfw: Downloading m3u8 information\n",
    "[info] BIKhTvCNzfw: Downloading subtitles: pt-orig\n",
    "[info] BIKhTvCNzfw: Downloading 1 format(s): 136+251\n",
    "Deleting existing file cl_st1_eduardo_cvdc/4 - Análise do discurso - Coleção linguística para ensino superior..pt-orig.vtt\n",
    "[info] Writing video subtitles to: cl_st1_eduardo_cvdc/4 - Análise do discurso - Coleção linguística para ensino superior..pt-orig.vtt\n",
    "[download] Destination: cl_st1_eduardo_cvdc/4 - Análise do discurso - Coleção linguística para ensino superior..pt-orig.vtt\n",
    "[download] 100% of   43.51KiB in 00:00:00 at 382.87KiB/s\n",
    "[download] Downloading item 5 of 5\n",
    "[youtube] Extracting URL: https://www.youtube.com/watch?v=NWYO-K-cWkk\n",
    "[youtube] NWYO-K-cWkk: Downloading webpage\n",
    "[youtube] NWYO-K-cWkk: Downloading ios player API JSON\n",
    "[youtube] NWYO-K-cWkk: Downloading web creator player API JSON\n",
    "[youtube] NWYO-K-cWkk: Downloading m3u8 information\n",
    "[info] NWYO-K-cWkk: Downloading subtitles: pt-orig\n",
    "[info] NWYO-K-cWkk: Downloading 1 format(s): 605+140\n",
    "Deleting existing file cl_st1_eduardo_cvdc/5 - Linguística IV   Aula 01   Introduçãoà Análise do Discurso.pt-orig.vtt\n",
    "[info] Writing video subtitles to: cl_st1_eduardo_cvdc/5 - Linguística IV   Aula 01   Introduçãoà Análise do Discurso.pt-orig.vtt\n",
    "[download] Destination: cl_st1_eduardo_cvdc/5 - Linguística IV   Aula 01   Introduçãoà Análise do Discurso.pt-orig.vtt\n",
    "[download] 100% of  138.98KiB in 00:00:00 at 282.59KiB/s\n",
    "[download] Finished downloading playlist: cl_st1_eduardo_cvdc\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_eduardo$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614bbaf8-c798-48ac-adbe-7e2516aab1e2",
   "metadata": {},
   "source": [
    "#### Checking the downloaded captions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706812f-e843-4b3e-a8f9-fe177cb68066",
   "metadata": {},
   "source": [
    "```\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_eduardo$ ll\n",
    "total 1355677\n",
    "drwxrwxrwx 1 eyamrog eyamrog       512 Aug  7 17:19  ./\n",
    "drwxrwxrwx 1 eyamrog eyamrog       512 Jul 19 07:37  ../\n",
    "-rwxrwxrwx 1 eyamrog eyamrog     17459 Aug  7 17:19 'Apresentando a Linguística de Corpus [QiyQHUGgmi4].pt-orig.vtt'*\n",
    "drwxrwxrwx 1 eyamrog eyamrog       512 Aug  7 17:26  cl_st1_eduardo_cvdc/\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_eduardo$ cd cl_st1_eduardo_cvdc/\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_eduardo/cl_st1_eduardo_cvdc$ ll\n",
    "total 776\n",
    "drwxrwxrwx 1 eyamrog eyamrog    512 Aug  7 17:26  ./\n",
    "drwxrwxrwx 1 eyamrog eyamrog    512 Aug  7 17:19  ../\n",
    "-rwxrwxrwx 1 eyamrog eyamrog  17459 Aug  7 17:26 '1 - Apresentando a Linguística de Corpus.pt-orig.vtt'*\n",
    "-rwxrwxrwx 1 eyamrog eyamrog  29347 Aug  7 17:26 '2 - O que é Linguística de Corpus？.pt-orig.vtt'*\n",
    "-rwxrwxrwx 1 eyamrog eyamrog 549179 Aug  7 17:26 '3 - Aula aberta - Linguística de Corpus para Tradutores.pt-orig.vtt'*\n",
    "-rwxrwxrwx 1 eyamrog eyamrog  44559 Aug  7 17:26 '4 - Análise do discurso - Coleção linguística para ensino superior..pt-orig.vtt'*\n",
    "-rwxrwxrwx 1 eyamrog eyamrog 142313 Aug  7 17:26 '5 - Linguística IV   Aula 01   Introduçãoà Análise do Discurso.pt-orig.vtt'*\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_eduardo/cl_st1_eduardo_cvdc$ head -n 20 '1 - Apresentando a Linguística de Corpus.pt-orig.vtt'\n",
    "WEBVTT\n",
    "Kind: captions\n",
    "Language: pt\n",
    "\n",
    "00:00:20.520 --> 00:00:23.780 align:start position:0%\n",
    "\n",
    "a<00:00:21.210><c> lingüística</c><00:00:21.780><c> de</c><00:00:22.170><c> cordas</c><00:00:22.830><c> é</c><00:00:23.100><c> uma</c><00:00:23.370><c> área</c><00:00:23.640><c> da</c>\n",
    "\n",
    "00:00:23.780 --> 00:00:23.790 align:start position:0%\n",
    "a lingüística de cordas é uma área da\n",
    "\n",
    "\n",
    "00:00:23.790 --> 00:00:26.570 align:start position:0%\n",
    "a lingüística de cordas é uma área da\n",
    "lingüística<00:00:24.450><c> aplicada</c><00:00:24.590><c> que</c><00:00:25.590><c> se</c><00:00:25.740><c> ocupa</c><00:00:26.310><c> da</c>\n",
    "\n",
    "00:00:26.570 --> 00:00:26.580 align:start position:0%\n",
    "lingüística aplicada que se ocupa da\n",
    "\n",
    "\n",
    "(my_env) eyamrog@Rog-ASUS:/mnt/c/Users/eyamr/Downloads/cl_st1_eduardo/cl_st1_eduardo_cvdc$\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99f1d63-2763-42e8-ab4c-baec8549a9a6",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cccf6f7c-f97d-4839-b175-2fabda00d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webvtt\n",
    "import pandas as pd\n",
    "import demoji\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2267a1b-4b57-433e-b410-b7adc3d849b9",
   "metadata": {},
   "source": [
    "## Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab00e06-833e-4e30-bc33-e517efdff7b0",
   "metadata": {},
   "source": [
    "### Defining the input and output directory names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ac07d7-1d5c-4055-ba3d-17281b196013",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = 'cl_st1_eduardo_cvdc'\n",
    "output_directory = input_directory + '-output'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99aeff6-30d7-4546-954d-0233c1ea5711",
   "metadata": {},
   "source": [
    "### Defining a function to extract caption texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ba783b-de63-4c86-958f-d436313f338d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_caption_text(webvtt_file, caption_file):\n",
    "    vtt = webvtt.read(webvtt_file)\n",
    "    \n",
    "    # Writing the text of the caption to the output file\n",
    "    with open(caption_file, 'w', encoding='utf-8') as f:\n",
    "        f.write('text' + '\\n') # Includes the header that will be used in the dataframe\n",
    "        for caption in vtt:\n",
    "            f.write(caption.text + '\\n')\n",
    "    \n",
    "    # Deduplicating the text of the caption using a dataframe\n",
    "    df = pd.read_table(caption_file)\n",
    "    df['text'] = df['text'].map(str)\n",
    "    df.drop_duplicates(subset='text', keep='first', inplace=True)\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Creating a single string containing all 'text' values separated by spaces\n",
    "    text_line = ' '.join(df['text'])\n",
    "\n",
    "    # Rewriting the output file with the single string\n",
    "    with open(caption_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(text_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45781edd-5e00-4045-81e5-2091f6af0424",
   "metadata": {},
   "source": [
    "### Defining a function to recursively process the `input_directory` and store the results in `output_directory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "980939ff-ebd0-4c59-b0f0-1c6d8574e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(input_directory, output_directory):\n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.vtt'):\n",
    "                # Constructing the corresponding caption filename\n",
    "                base_name = os.path.splitext(filename)[0]\n",
    "                caption_filename = base_name + '.txt'\n",
    "\n",
    "                # Creating the output subdirectory structure\n",
    "                relative_path = os.path.relpath(root, input_directory)\n",
    "                output_subdir = os.path.join(output_directory, relative_path)\n",
    "                os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "                # Full paths for input and output files\n",
    "                input_file_path = os.path.join(root, filename)\n",
    "                output_file_path = os.path.join(output_subdir, caption_filename)\n",
    "\n",
    "                # Calling 'extract_caption_text' function\n",
    "                extract_caption_text(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf2a72-cdd6-4668-9a2e-67dd3246c8bc",
   "metadata": {},
   "source": [
    "### Processing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f806e84-70a8-4c5c-a9f7-1d4b063b26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_directory(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9251b422-7a91-4347-b3e1-20e388e66795",
   "metadata": {},
   "source": [
    "### Importing the texts into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b7cee5-719e-423a-8b61-e60a7a452328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_contents(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    except Exception as e:\n",
    "        print(f'Error reading file {file_path}: {e}')\n",
    "        return None\n",
    "\n",
    "def process_output_directory(output_directory):\n",
    "    # Initialize an empty list to store data\n",
    "    data = []\n",
    "\n",
    "    # Recursively iterate through the output_directory\n",
    "    for root, _, files in os.walk(output_directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            file_contents = read_file_contents(file_path)\n",
    "            if file_contents is not None:\n",
    "                data.append({'text': file_contents, 'filepath': file_path})\n",
    "\n",
    "    # Create a DataFrame from the collected data\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Importing the texts into the dataframe 'df_tweets_filtered'. Even though this study does not relate to 'tweets', this dataframe name is adopted in order to enable code reuse in subsequent processing stages\n",
    "df_tweets_filtered = process_output_directory(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4f3e288-9ff6-48a3-a2bd-d1ff0faf02e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a lingüística de cordas é uma área da lingüíst...</td>\n",
       "      <td>cl_st1_eduardo_cvdc-output\\1 - Apresentando a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Música] Olá que bom tê-los conosco para mais ...</td>\n",
       "      <td>cl_st1_eduardo_cvdc-output\\2 - O que é Linguís...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o ok acho que agora tá ao vivo né gente posso ...</td>\n",
       "      <td>cl_st1_eduardo_cvdc-output\\3 - Aula aberta - L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e aí o nome sebastião gostaria de apresentar a...</td>\n",
       "      <td>cl_st1_eduardo_cvdc-output\\4 - Análise do disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Olá meus nobres alunos de letras da unitins se...</td>\n",
       "      <td>cl_st1_eduardo_cvdc-output\\5 - Linguística IV ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  a lingüística de cordas é uma área da lingüíst...   \n",
       "1  [Música] Olá que bom tê-los conosco para mais ...   \n",
       "2  o ok acho que agora tá ao vivo né gente posso ...   \n",
       "3  e aí o nome sebastião gostaria de apresentar a...   \n",
       "4  Olá meus nobres alunos de letras da unitins se...   \n",
       "\n",
       "                                            filepath  \n",
       "0  cl_st1_eduardo_cvdc-output\\1 - Apresentando a ...  \n",
       "1  cl_st1_eduardo_cvdc-output\\2 - O que é Linguís...  \n",
       "2  cl_st1_eduardo_cvdc-output\\3 - Aula aberta - L...  \n",
       "3  cl_st1_eduardo_cvdc-output\\4 - Análise do disc...  \n",
       "4  cl_st1_eduardo_cvdc-output\\5 - Linguística IV ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82444f9-07ff-4fda-a42c-72a0f181dfc1",
   "metadata": {},
   "source": [
    "### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "010ae9db-d403-4f10-a9ba-afd9852e5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered.to_csv('tweets_emojified.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26439fc-15e9-48fc-a3e9-173e9e444b23",
   "metadata": {},
   "source": [
    "## Replacing emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f1e24f-a461-406b-be27-216e76f8a1e9",
   "metadata": {},
   "source": [
    "### Demojifying the column `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58feed56-8518-48cc-a754-4a14f70a9544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to demojify a string\n",
    "def demojify_line(input_line):\n",
    "    demojified_line = demoji.replace_with_desc(input_line, sep='<em>')\n",
    "    return demojified_line\n",
    "\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(demojify_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f963c5a1-342f-4af4-82f9-5126d1734153",
   "metadata": {},
   "source": [
    "#### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87323b73-6399-4c97-9885-c07c5e283924",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered.to_csv('tweets_demojified1.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f29602d-078c-48de-bbce-fae5dd8dc6c4",
   "metadata": {},
   "source": [
    "### Separating the demojified strings with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdaed365-32e1-4c66-8436-976216ed0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to separate the demojified strings with spaces\n",
    "def preprocess_line(input_line):\n",
    "    # Add a space before the first delimiter '<em>', if it is not already preceded by one\n",
    "    preprocessed_line = re.sub(r'(?<! )<em>', ' <em>', input_line)\n",
    "    # Add a space after the first delimiter '<em>', if it is not already followed by one\n",
    "    preprocessed_line = re.sub(r'<em>(?! )', '<em> ', preprocessed_line)\n",
    "    return preprocessed_line\n",
    "\n",
    "# Separating the demojified strings with spaces\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(preprocess_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1a149-b78e-497f-b808-69c292e2d667",
   "metadata": {},
   "source": [
    "#### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aea2c278-ae25-4b97-9cf9-14d6d1138038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered.to_csv('tweets_demojified2.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60228e2-0458-4a8f-b5a6-584c87ae1eeb",
   "metadata": {},
   "source": [
    "### Formatting the demojified strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52b6b3d0-e68a-453d-8411-b096e8600eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to format the demojified string\n",
    "def format_demojified_string(input_line):\n",
    "    # Defining a function to format the demojified string using RegEx\n",
    "    def process_demojified_string(s):\n",
    "            # Lowercase the string\n",
    "            s = s.lower()\n",
    "            # Replace spaces and colons followed by a space with underscores\n",
    "            s = re.sub(r'(: )| ', '_', s)\n",
    "            # Add the appropriate prefixes and suffixes\n",
    "            s = f'EMOJI{s}e'\n",
    "            return s\n",
    "\n",
    "    # Use RegEx to find and process each demojified string\n",
    "    processed_line = re.sub(r'<em>(.*?)<em>', lambda match: process_demojified_string(match.group(1)), input_line)\n",
    "    return processed_line\n",
    "\n",
    "# Formatting the demojified strings\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(format_demojified_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72350b09-5b20-4e8b-830b-ce3d48d8f4fe",
   "metadata": {},
   "source": [
    "### Replacing the `pipe` character by the `-` character in the `text` column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0d9c4c-a152-4245-965a-8ca466582bd5",
   "metadata": {},
   "source": [
    "Further on, a few columns of the dataframe are going to be exported into the file `tweets.txt` whose columns need to be delimited by the `pipe` character. Therefore, it is recommended that any occurrences of the `pipe` character in the `text` column are replaced by another character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a15f9969-5823-4a07-bcf4-28350f348da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to replace the 'pipe' character by the '-' character\n",
    "def replace_pipe_with_hyphen(input_string):\n",
    "    modified_string = re.sub(r'\\|', '-', input_string)\n",
    "    return modified_string\n",
    "\n",
    "# Replacing the 'pipe' character by the '-' character\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(replace_pipe_with_hyphen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d56155-4d67-4eda-9ddd-775269031bca",
   "metadata": {},
   "source": [
    "#### Exporting the filtered data into a file for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68abd515-ff7e-4ae6-9a79-b3ddd2b822f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered.to_csv('tweets_demojified3.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c18de9a-6496-4d3a-bbac-0624d2b6c9ec",
   "metadata": {},
   "source": [
    "## Tokenising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59401425-7372-4c34-8f92-f5c5343cd730",
   "metadata": {},
   "source": [
    "Please refer to [What is tokenization in NLP?](https://www.analyticsvidhya.com/blog/2020/05/what-is-tokenization-nlp/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bb76661-222d-4d9f-8ca6-619c1dd4861d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to tokenise a string\n",
    "def tokenise_string(input_line):\n",
    "    # Replace URLs with placeholders\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\\b'\n",
    "    placeholder = '<URL>'  # Choose a unique placeholder\n",
    "    urls = re.findall(url_pattern, input_line)\n",
    "    tokenised_line = re.sub(url_pattern, placeholder, input_line)  # Replace URLs with placeholders\n",
    "    \n",
    "    # Replace curly quotes with straight ones\n",
    "    tokenised_line = tokenised_line.replace('“', '\"').replace('”', '\"').replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "    # Separate common punctuation marks with spaces\n",
    "    tokenised_line = re.sub(r'([.\\!?,\"\\'/()])', r' \\1 ', tokenised_line)\n",
    "    # Add a space before '#'\n",
    "    tokenised_line = re.sub(r'(?<!\\s)#', r' #', tokenised_line)  # Add a space before '#' if it is not already preceded by one\n",
    "    # Reduce extra spaces by a single space\n",
    "    tokenised_line = re.sub(r'\\s+', ' ', tokenised_line)\n",
    "    \n",
    "    # Replace the placeholders with the respective URLs\n",
    "    for url in urls:\n",
    "        tokenised_line = tokenised_line.replace(placeholder, url, 1)\n",
    "    \n",
    "    return tokenised_line\n",
    "\n",
    "# Tokenising the strings\n",
    "df_tweets_filtered['text'] = df_tweets_filtered['text'].apply(tokenise_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f456e6-3308-4451-b0dc-8969a342dd23",
   "metadata": {},
   "source": [
    "## Creating the files `file_index.txt` and `tweets.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caed102-dd11-48f0-8f00-33d6c5519790",
   "metadata": {},
   "source": [
    "### Creating column `text_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2181add-6594-4445-8fa3-639ca9301093",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['text_id'] = 't' + df_tweets_filtered.index.astype(str).str.zfill(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51ec334-7592-45e6-a8fb-61cb74bfcdc0",
   "metadata": {},
   "source": [
    "### Creating column `conversation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71f8fb7f-e0b2-49bb-8ad7-1700547e6962",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['conversation'] = 'v:' + df_tweets_filtered['filepath']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116c789-c706-4c25-9278-bf03fa301f34",
   "metadata": {},
   "source": [
    "#### Replacing space by the `_` character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dae8d8a-e064-4619-9353-400ad145b4c5",
   "metadata": {},
   "source": [
    "**Important**: Since the strings in the original columns contain spaces, Pandas creates `file_index.txt` with the columns enclosed with `\"` - this caracter causes issues in `examples.sh` when it is executed. Therefore, spaces should be replaced by another character such as underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2735ce4e-a3e0-4097-b01e-96e0c50f3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to replace space by the '_' character\n",
    "def replace_space_with_underscore(input_string):\n",
    "    modified_string = re.sub(r' ', '_', input_string)\n",
    "    return modified_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d961c5dc-3db6-4788-8831-e47324d4a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing space by the '_' character\n",
    "df_tweets_filtered['conversation'] = df_tweets_filtered['conversation'].apply(replace_space_with_underscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c7a46-55c0-4c21-bc59-5719047db60a",
   "metadata": {},
   "source": [
    "### Creating column `date`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690fa438-ace7-488e-ab16-afe38c24d239",
   "metadata": {},
   "source": [
    "The date for all texts are defined as the date Guilherme sent the dataset, 16th April, 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6c75b91-befc-4cb6-88d2-4b26262280b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['date'] = 'd:' + '2024-04-16'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85d2c3-f39c-42eb-8fae-56e01a630f07",
   "metadata": {},
   "source": [
    "### Creating column `text_url`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d9321-4e32-40ba-b42b-92318176e4e2",
   "metadata": {},
   "source": [
    "No URL was considered for all texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48ec32af-d94a-43fe-a4a9-e6acb1c9b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['text_url'] = 'url:' + 'no_url'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe12db7-be63-47d8-9e78-97ee8a25c03b",
   "metadata": {},
   "source": [
    "### Creating column `user`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8edc7d-474d-4c4a-9291-e37c6dcc513e",
   "metadata": {},
   "source": [
    "`various_speakers` was considered for all texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45d56b01-2ad6-4b7f-a6c1-984bccaf60bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['user'] = 'u:' + 'various_speakers'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e775aabe-ed61-45a6-8663-d0b9ae95e1b5",
   "metadata": {},
   "source": [
    "### Creating column `content`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf145c04-8a3a-4f94-bbaa-9651a3aeaefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered['content'] = 'c:' + df_tweets_filtered['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37c9710-a506-426b-bfbd-bd71d5a45402",
   "metadata": {},
   "source": [
    "### Reordering the created columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d69e49-612c-4ff5-9e19-51aef551fe26",
   "metadata": {},
   "source": [
    "Please refer to:\n",
    "- [Python - List Comprehension 1](https://www.w3schools.com/python/python_lists_comprehension.asp)\n",
    "- [Python - List Comprehension 2](https://treyhunner.com/2015/12/python-list-comprehensions-now-in-color/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f73ff13f-40d3-4615-b1e4-58ffb01366ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns (we use list comprehension to create a list of all columns except 'text_id', 'variable', 'date' and 'text_url')\n",
    "df_tweets_filtered = df_tweets_filtered[['text_id', 'conversation', 'date', 'text_url', 'user', 'content'] + [col for col in df_tweets_filtered.columns if col not in ['text_id', 'conversation', 'date', 'text_url', 'user', 'content']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e8aa25c-cde7-4893-8443-1a6677ce3927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>conversation</th>\n",
       "      <th>date</th>\n",
       "      <th>text_url</th>\n",
       "      <th>user</th>\n",
       "      <th>content</th>\n",
       "      <th>text</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t000000</td>\n",
       "      <td>v:cl_st1_eduardo_cvdc-output\\1_-_Apresentando_...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:a lingüística de cordas é uma área da lingüí...</td>\n",
       "      <td>a lingüística de cordas é uma área da lingüíst...</td>\n",
       "      <td>cl_st1_eduardo_cvdc-output\\1 - Apresentando a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t000001</td>\n",
       "      <td>v:cl_st1_eduardo_cvdc-output\\2_-_O_que_é_Lingu...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:[Música] Olá que bom tê-los conosco para mai...</td>\n",
       "      <td>[Música] Olá que bom tê-los conosco para mais ...</td>\n",
       "      <td>cl_st1_eduardo_cvdc-output\\2 - O que é Linguís...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t000002</td>\n",
       "      <td>v:cl_st1_eduardo_cvdc-output\\3_-_Aula_aberta_-...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:o ok acho que agora tá ao vivo né gente poss...</td>\n",
       "      <td>o ok acho que agora tá ao vivo né gente posso ...</td>\n",
       "      <td>cl_st1_eduardo_cvdc-output\\3 - Aula aberta - L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t000003</td>\n",
       "      <td>v:cl_st1_eduardo_cvdc-output\\4_-_Análise_do_di...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:e aí o nome sebastião gostaria de apresentar...</td>\n",
       "      <td>e aí o nome sebastião gostaria de apresentar a...</td>\n",
       "      <td>cl_st1_eduardo_cvdc-output\\4 - Análise do disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t000004</td>\n",
       "      <td>v:cl_st1_eduardo_cvdc-output\\5_-_Linguística_I...</td>\n",
       "      <td>d:2024-04-16</td>\n",
       "      <td>url:no_url</td>\n",
       "      <td>u:silas_malafaia</td>\n",
       "      <td>c:Olá meus nobres alunos de letras da unitins ...</td>\n",
       "      <td>Olá meus nobres alunos de letras da unitins se...</td>\n",
       "      <td>cl_st1_eduardo_cvdc-output\\5 - Linguística IV ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text_id                                       conversation          date  \\\n",
       "0  t000000  v:cl_st1_eduardo_cvdc-output\\1_-_Apresentando_...  d:2024-04-16   \n",
       "1  t000001  v:cl_st1_eduardo_cvdc-output\\2_-_O_que_é_Lingu...  d:2024-04-16   \n",
       "2  t000002  v:cl_st1_eduardo_cvdc-output\\3_-_Aula_aberta_-...  d:2024-04-16   \n",
       "3  t000003  v:cl_st1_eduardo_cvdc-output\\4_-_Análise_do_di...  d:2024-04-16   \n",
       "4  t000004  v:cl_st1_eduardo_cvdc-output\\5_-_Linguística_I...  d:2024-04-16   \n",
       "\n",
       "     text_url              user  \\\n",
       "0  url:no_url  u:silas_malafaia   \n",
       "1  url:no_url  u:silas_malafaia   \n",
       "2  url:no_url  u:silas_malafaia   \n",
       "3  url:no_url  u:silas_malafaia   \n",
       "4  url:no_url  u:silas_malafaia   \n",
       "\n",
       "                                             content  \\\n",
       "0  c:a lingüística de cordas é uma área da lingüí...   \n",
       "1  c:[Música] Olá que bom tê-los conosco para mai...   \n",
       "2  c:o ok acho que agora tá ao vivo né gente poss...   \n",
       "3  c:e aí o nome sebastião gostaria de apresentar...   \n",
       "4  c:Olá meus nobres alunos de letras da unitins ...   \n",
       "\n",
       "                                                text  \\\n",
       "0  a lingüística de cordas é uma área da lingüíst...   \n",
       "1  [Música] Olá que bom tê-los conosco para mais ...   \n",
       "2  o ok acho que agora tá ao vivo né gente posso ...   \n",
       "3  e aí o nome sebastião gostaria de apresentar a...   \n",
       "4  Olá meus nobres alunos de letras da unitins se...   \n",
       "\n",
       "                                            filepath  \n",
       "0  cl_st1_eduardo_cvdc-output\\1 - Apresentando a ...  \n",
       "1  cl_st1_eduardo_cvdc-output\\2 - O que é Linguís...  \n",
       "2  cl_st1_eduardo_cvdc-output\\3 - Aula aberta - L...  \n",
       "3  cl_st1_eduardo_cvdc-output\\4 - Análise do disc...  \n",
       "4  cl_st1_eduardo_cvdc-output\\5 - Linguística IV ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d29640-56d7-4520-8ed6-3cbcba53e401",
   "metadata": {},
   "source": [
    "### Creating the file `file_index.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9fa478d-42c2-4744-826e-eda5ef749642",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text_id', 'conversation', 'date', 'text_url']].to_csv('file_index.txt', sep=' ', index=False, header=False, encoding='utf-8', lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901681d2-47ce-45f3-a258-26001dd4af1f",
   "metadata": {},
   "source": [
    "### Creating the file `tweets.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d096fbb9-0878-477f-9a83-1220b9d0aff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder tweets created!\n"
     ]
    }
   ],
   "source": [
    "folder = 'tweets'\n",
    "try:\n",
    "    os.mkdir(folder)\n",
    "    print(f'Folder {folder} created!')\n",
    "except FileExistsError:\n",
    "    print(f'Folder {folder} already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc145c-7756-4fe0-ad9a-4e8df2afa1b4",
   "metadata": {},
   "source": [
    "Note: The parameters `doublequote=False` and `escapechar=' '` are required to avoid that the column content is doublequoted with '\"' in sentences that use characters that need to be escaped such as double quote '\"' itself - this causes a malformed response from TreeTagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4d1aacf-847c-43f2-ada7-2cd0cb7eb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_filtered[['text_id', 'conversation', 'date', 'user', 'content']].to_csv(f'{folder}/tweets.txt', sep='|', index=False, header=False, encoding='utf-8', lineterminator='\\n', doublequote=False, escapechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af67c534-3fc1-4cbd-8858-836c321fef82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
